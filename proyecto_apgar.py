# -*- coding: utf-8 -*-
"""Proyecto_APGAR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kxvyMle5GbgmwG8peeJ0_dkaUAbdpOHO

#**Predicción de la Puntuación APGAR en Recién Nacidos mediante Aprendizaje Automático**

**Objetivo:**
<br>
Desarrollar y evaluar modelos predictivos robustos para predecir la puntuación APGAR, identificando factores clave que puedan ayudar en la intervención temprana en el contexto perinatal.

##**Librerias:**
"""

import pandas as pd
from sklearn.model_selection import train_test_split        # Preparar datos para modelado
from sklearn.ensemble import RandomForestRegressor          # Random Forest
from sklearn.metrics import mean_squared_error, r2_score    # Random Forest
from sklearn.linear_model import LinearRegression           # Regresión Lineal
from sklearn.neighbors import KNeighborsRegressor           # KNN
import matplotlib.pyplot as plt                             # Comparar Modelos

from sklearn.metrics import mean_squared_error              # Evaluar modelos

"""##**Cargar y Pre-Procesar los Datos:**
Cargamos el archivo de datos y preparamos las variables para que los modelos de Machine Learning puedan trabajar con ellas. Esto incluye eliminar valores faltantes y convertir categorías en números.
"""

# Cargar el dataset
data = pd.read_csv('/content/Datos_Nacimientos_DIRESA.csv')

# Revisar las primeras filas
print(data.head())

# Convertir las variables categóricas en variables numéricas
data['sexo_nacido'] = data['sexo_nacido'].map({'FEMENINO': 0, 'MASCULINO': 1})
data['Lactancia_Precoz'] = data['Lactancia_Precoz'].map({'SI': 1, 'NO': 0})
data['Estado_Civil'] = data['Estado_Civil'].map({'CASADO': 0, 'SOLTERO': 1, 'CONVIVIENTE': 2, 'DIVORCIADO': 3})
data['Condicion_Parto'] = data['Condicion_Parto'].map({'CESAREA': 0, 'ESPONTANEO': 1, 'INSTRUMENTADO': 2, 'OTRO': 3})
data['Tipo_Parto'] = data['Tipo_Parto'].map({'UNICO': 0, 'DOBLE': 1, 'TRIPLE': 2})

# Asegurarse de que no haya valores nulos en las columnas relevantes
data = data.dropna(subset=['PESO_NACIDO', 'TALLA_NACIDO', 'APGAR_5_NACIDO', 'DUR_EMB_PARTO', 'Edad_Madre'])

# Eliminar todas las filas que contengan NaN en cualquier columna
data = data.dropna()

# Revisar la estadística descriptiva
print(data.describe())

"""##**Preparar los Datos para el Modelado**
Aquí dividimos los datos en dos partes:
*   Características (X): Las variables que usaremos para predecir (por ejemplo,peso, talla, tipo de parto).
*   Objetivo (y): La variable que queremos predecir, en este caso, la puntuación APGAR.

Además, dividimos los datos en entrenamiento (80%) y prueba (20%) para poder entrenar y probar nuestros modelos de manera confiable.
"""

# Selección de las características (X) y la variable objetivo (y)
X = data[['PESO_NACIDO', 'TALLA_NACIDO', 'DUR_EMB_PARTO', 'Edad_Madre', 'sexo_nacido',
          'Tipo_Parto', 'Condicion_Parto', 'Lactancia_Precoz', 'Estado_Civil']]
y = data['APGAR_5_NACIDO']

# División en datos de entrenamiento y prueba (80% entrenamiento, 20% prueba)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(X_train.shape, X_test.shape)

"""##**Entrenar el Modelo de Random Forest**
El modelo Random Forest es un algoritmo de Machine Learning que crea múltiples árboles de decisión para hacer predicciones más robustas y precisas.
"""

# Modelo Random Forest
rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# Predicciones
y_pred_rf = rf.predict(X_test)

# Evaluación
mse_rf = mean_squared_error(y_test, y_pred_rf)
r2_rf = r2_score(y_test, y_pred_rf)

print(f'Random Forest - MSE: {mse_rf}, R^2: {r2_rf}')

"""##**Entrenar el Modelo de Regresión Lineal**
La Regresión Lineal es un modelo simple que se utiliza para predecir un valor numérico (como la puntuación APGAR) a partir de las características.
"""

# Modelo Regresión Lineal
lr = LinearRegression()
lr.fit(X_train, y_train)

# Predicciones
y_pred_lr = lr.predict(X_test)

# Evaluación
mse_lr = mean_squared_error(y_test, y_pred_lr)
r2_lr = r2_score(y_test, y_pred_lr)

print(f'Regresión Lineal - MSE: {mse_lr}, R^2: {r2_lr}')

"""##**Entrenar el Modelo K-Nearest Neighbors (KNN)**
El modelo KNN (K-Vecinos más Cercanos) predice el valor de una observación según los valores de sus vecinos más cercanos. Es otro enfoque para la predicción.
"""

# Modelo KNN
knn = KNeighborsRegressor(n_neighbors=5)
knn.fit(X_train, y_train)

# Predicciones
y_pred_knn = knn.predict(X_test)

# Evaluación
mse_knn = mean_squared_error(y_test, y_pred_knn)
r2_knn = r2_score(y_test, y_pred_knn)

print(f'KNN - MSE: {mse_knn}, R^2: {r2_knn}')

"""##**Comparar los Modelos**
Aquí comparamos los tres modelos utilizando sus métricas de MSE y R² para ver cuál de ellos tiene el mejor rendimiento.
"""

# Comparación de los modelos
plt.figure(figsize=(12, 6))

# Random Forest
plt.subplot(1, 3, 1)
plt.scatter(y_test, y_pred_rf, color='blue', alpha=0.5)
plt.plot([0, 10], [0, 10], color='red', linestyle='--')
plt.title('Random Forest')
plt.xlabel('Real')
plt.ylabel('Predicción')

# Regresión Lineal
plt.subplot(1, 3, 2)
plt.scatter(y_test, y_pred_lr, color='green', alpha=0.5)
plt.plot([0, 10], [0, 10], color='red', linestyle='--')
plt.title('Regresión Lineal')
plt.xlabel('Real')
plt.ylabel('Predicción')

# KNN
plt.subplot(1, 3, 3)
plt.scatter(y_test, y_pred_knn, color='orange', alpha=0.5)
plt.plot([0, 10], [0, 10], color='red', linestyle='--')
plt.title('KNN')
plt.xlabel('Real')
plt.ylabel('Predicción')

plt.tight_layout()
plt.show()

"""##**Evaluación de los modelos**

"""

# Evaluación del modelo Random Forest
y_pred_rf = rf.predict(X_test)
r2_rf = rf.score(X_test, y_test)
rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))

print(f"Random Forest - R^2: \t\t{r2_rf}")
print(f"Random Forest - RMSE: \t\t{rmse_rf}")

# Evaluación del modelo de Regresión Lineal
y_pred_lr = lr.predict(X_test)
r2_lr = lr.score(X_test, y_test)
rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))

print(f"Regresión Lineal - R^2: \t{r2_lr}")
print(f"Regresión Lineal - RMSE: \t{rmse_lr}")

# Evaluación del modelo KNN
y_pred_knn = knn.predict(X_test)
r2_knn = knn.score(X_test, y_test)
rmse_knn = np.sqrt(mean_squared_error(y_test, y_pred_knn))

print(f"KNN - R^2: \t\t\t{r2_knn}")
print(f"KNN - RMSE: \t\t\t{rmse_knn}")

"""###Interpretación:

1.   Random Forest
  *   R²: 0.5119: Este valor indica que el modelo Random Forest explica aproximadamente el 51.19% de la variabilidad de los datos. Aunque no es excelente, está funcionando razonablemente bien, ya que un R² cercano a 1 indica una muy buena predicción, y valores cercanos a 0 indican un mal desempeño.
  *   RMSE: 6.02: Este valor nos da la magnitud del error promedio entre las predicciones y los valores reales. En este caso, el error promedio es de aproximadamente 6.02 unidades. Un RMSE bajo indica que el modelo está haciendo buenas predicciones en comparación con los valores reales.


2.   Regresión Lineal
  *   R²: 0.0029: Este valor indica que el modelo de regresión lineal apenas explica el 0.29% de la variabilidad de los datos, lo que significa que el modelo no está ajustando bien los datos. Este es un indicador claro de que la regresión lineal no es adecuada para este conjunto de datos o para el tipo de relación que existe entre las variables.
  *   RMSE: 8.61: El error promedio es de 8.61 unidades, lo que indica que las predicciones del modelo son menos precisas que las de Random Forest.


3.   KNN
  *   R²: -0.1096: Un valor negativo de R² significa que el modelo KNN está realizando predicciones peores que simplemente predecir la media de los valores. Este es un mal resultado, ya que sugiere que el modelo está sobreajustando o no está capturando la relación en los datos.
  *   RMSE: 9.08: Este es el mayor valor de RMSE de los tres modelos, lo que confirma que las predicciones del modelo KNN son las menos precisas.

###Análisis:

*   **Random Forest** está funcionando mejor que los otros dos modelos, aunque aún se puede mejorar. Tiene un R² decente y el RMSE más bajo, lo que indica que tiene un buen rendimiento general en este conjunto de datos.

*   **Regresión Lineal** está teniendo un desempeño muy pobre. El valor de R² es muy bajo, lo que sugiere que la relación entre las variables es más compleja y no puede ser modelada adecuadamente con una simple regresión lineal.

*   **KNN** también está teniendo un desempeño negativo (R² negativo), lo que sugiere que este modelo no está funcionando bien para el conjunto de datos. El valor de RMSE más alto también lo confirma.

###Conclusión:

Después de evaluar los tres modelos, Random Forest ha demostrado ser el modelo más prometedor, con un rendimiento razonable en cuanto a R² y RMSE. Aunque no es perfecto, su R² de 0.51 indica que puede capturar una cantidad significativa de la variabilidad en los datos. En comparación, tanto la Regresión Lineal como KNN no han logrado generar buenos resultados, con valores negativos de R² y altos valores de RMSE, lo que sugiere que no son adecuados para este conjunto de datos.

Dado el rendimiento positivo de Random Forest, se recomienda proceder con el ajuste de sus hiperparámetros utilizando técnicas como GridSearchCV. Esta estrategia permitirá explorar de manera eficiente un espacio de hiperparámetros más amplio sin caer en un sobreajuste. Si bien un ajuste más fino puede mejorar aún más el rendimiento, es crucial encontrar un equilibrio entre la mejora de los hiperparámetros y la evitación del sobreajuste, asegurándose de que el modelo generalice bien a nuevos datos. Un ajuste excesivo puede llevar a un modelo que se adapta demasiado a las particularidades del conjunto de entrenamiento, comprometiendo su capacidad para predecir en situaciones reales.

####Codigo para el ajuste de hiperparámetros
"""

from sklearn.model_selection import GridSearchCV

# Definir el modelo de Random Forest
rf = RandomForestRegressor(random_state=42)

# Definir los hiperparámetros para la búsqueda
param_grid = {
    'n_estimators': [100, 200, 500],
    'max_depth': [10, 20, 30, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['sqrt', 'log2', None],
    'bootstrap': [True, False]
}

# Búsqueda en cuadrícula
grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)
grid_search.fit(X_train, y_train)

# Mejor combinación de hiperparámetros
print(f"Mejores hiperparámetros: {grid_search.best_params_}")

# Evaluación del modelo ajustado
best_rf = grid_search.best_estimator_
y_pred_best_rf = best_rf.predict(X_test)

# Evaluación de R^2 y RMSE
from sklearn.metrics import mean_squared_error, r2_score
rmse_best_rf = mean_squared_error(y_test, y_pred_best_rf, squared=False)
r2_best_rf = r2_score(y_test, y_pred_best_rf)

print(f"Mejor R²: {r2_best_rf}")
print(f"Mejor RMSE: {rmse_best_rf}")